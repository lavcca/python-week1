text="""
ì¸ìƒì€ ì§§ê³  ì‚¶ì€ ìƒê°ë³´ë‹¤ ë¹ ë¥´ê²Œ ì§€ë‚˜ê°„ë‹¤.
ì–´ë–¤ ë‚ ì€ ì¸ìƒì´ ì°¸ í˜ë“¤ê²Œ ëŠê»´ì§€ê³  ì–´ë–¤ ë‚ ì€ ì¸ìƒì´ ì•„ë¦„ë‹µê²Œ ëŠê»´ì§„ë‹¤.
ì‚¬ëŒë“¤ì€ ì‚¶ì—ì„œ ì„ íƒì„ í•˜ë©° ê·¸ ì„ íƒì´ ì¸ìƒì„ ë°”ê¾¼ë‹¤ê³  ë§í•œë‹¤.
ìš°ë¦¬ëŠ” ì¸ìƒì—ì„œ ì‹¤ìˆ˜ë¥¼ í†µí•´ ë°°ìš°ê³  ê³ í†µ ì†ì—ì„œ ì„±ì¥í•œë‹¤.
ì¸ìƒì€ í•­ìƒ ì‰½ì§€ ì•Šì§€ë§Œ ì¸ìƒì€ ìš°ë¦¬ì—ê²Œ ë§ì€ ê²ƒì„ ê°€ë¥´ì³ ì¤€ë‹¤.
Life is short and life is strange.
Sometimes life feels unfair, and sometimes it feels beautiful.
People say that life is about choices, and every choice matters.
In life, we learn from mistakes, and we grow from pain.
Life is not always easy, but life is always teaching us something.
"""

import pandas as pd
import re

clean_text = re.sub(r"[^a-zA-Z\s]", "", text.lower())
clean_text_kr = re.sub(r"[^ê°€-í£\s]", "", text)

tokens_raw = (clean_text + " " + clean_text_kr).split()

stopwords = {"is", "and", "a", "the", "to", "of"}
stopwords_kr = { "ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì—ì„œ", "ì—ê²Œ", "ì—ê²Œì„œ", "í•˜ì§€ë§Œ", "ê·¸ë¦¬ê³ ", "ì–´ë–¤", "ìš°ë¦¬ì—ê²Œ"}
all_stopwords = stopwords | stopwords_kr

s_raw = pd.Series(tokens_raw)

print("ğŸ“Œ ì „ì²´ ë‹¨ì–´ TOP 20")
print(s_raw.value_counts().head(20))

# Stopwords ì œê±°
def remove_josa(word):
    return re.sub(r"(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì—ì„œ|ì—ê²Œ|ì—ê²Œì„œ)$", "", word)

tokens_clean = []

for w in tokens_raw:
    w_clean = remove_josa(w)
    if w_clean and w_clean not in all_stopwords:
        tokens_clean.append(w_clean)

s_clean = pd.Series(tokens_clean)

print("\nğŸ“Œ Stopwords ì œê±° í›„ TOP 20")
print(s_clean.value_counts().head(20))
